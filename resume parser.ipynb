{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3a32ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divya Gupta\n",
      "Mobile No: +1(201)7240924 |Email id: dg3483@nyu.edu |Linkedin: https://www.linkedin.com/in/divya-gupta-66981a40/\n",
      "Education\n",
      "New York University Tandon School of Engineering Graduating Dec 2022\n",
      "MS in Computer Science, GPA 3.704\n",
      "•Coursework: Design and Analysis of Algorithm, Artificial Intelligence, Cloud Computing, Big Data, Operating\n",
      "System, Software Engineering, Principle Database Systems, and Machine Learning\n",
      "ABES Engineering College, AKTU Aug. 2010 - Jun 2014\n",
      "Bachelors of Technology in Computer Science, GPA 3.11\n",
      "Technical Skills\n",
      "Computer languages/ skills : Java, Python, C, JavaScript, Kafka, REST, Docker, PySpark, Hadoop, Hive, HTML,\n",
      "CSS, Pytorch, J2EE with struts and Hibernate, Django, flask\n",
      "Database : MYSQL, Cassandra, MongoDB\n",
      "Cloud Technologies : AWS S3, AWS Lambda, AWS Kinesis, AWS CloudFormation, AWS Opensearch, Heroku\n",
      "Other : GitHub, Agile, JIRA, Excel\n",
      "Projects\n",
      "•Facial Recognition System: Used Haar-Like feature algorithm for face detection and trained neural network for\n",
      "face recognition. Images are captured from live vedio streaming for training and testing purpose. Technologies\n",
      "used -: Open CV, python, java script, Jupiter notebook, TensorFlow\n",
      "•CareerConnect web application: Developed website using amazon cloud technologies where user just need to\n",
      "upload their resume. We scarped all user details and skill sets from their resume and based on results we are\n",
      "recommending people with similar skills set and job with similar skill requirements to them. Technologies used -:\n",
      "AWS S3, Open Search, Dynamodb, RDS, Cognito, Lambda, API Gateway, Python, Pyspark, nltk, JS, HTML\n",
      "•Nature’s call web application: Developed web application using scrum methodology to search nearest\n",
      "restrooms (public and private) in New York. Technologies used -: Python, Django framework, GitHub, HTML,\n",
      "Travis build for continuous integration and Heroku cloud for deployment.\n",
      "•Reservoir Sampling: Implemented Hadoop Map Reduce program in java to extract random K samples from back\n",
      "blaze Daily hard disk failure log data-set using Reservoir Sampling algorithm and performed Anomaly Detection of\n",
      "Hard Drive Failures in spark. Technologies used -: Hadoop Map Reduce, java, PySpark, Docker.\n",
      "•Photo Album web application: Created web application for an intelligent search where people can use text or\n",
      "voice to query for photos of people, objects, actions, landmarks and more. Technologies used -: Used AWS\n",
      "services like S3, LEX, Open Search, Rekognition, and transcribe, Python, HTML, JS, CSS\n",
      "•Dining Concierge chatbot: Created a Dining Concierge chatbot that sends people restaurant suggestions given\n",
      "a set of preferences that he/she provides the chatbot with through conversation. Technologies used -:AWS\n",
      "services like S3, Lambda, Open Search, DynamoDB, SQS, SNS, and LEX, HTML, CSS, JS, Python\n",
      "Work Experience\n",
      "Summer Internship 2022 (AWS) May 2022 - August 2022\n",
      "•Implemented real time middle ware data pipeline using micro-service architecture and Hadoop map reduce\n",
      "streaming.\n",
      "•Technologies used were Hadoop Streaming, Python, MongoDB, flask, Pandas, JS, HTML\n",
      "Functional Test Engineer (Amdocs India) Mar 2015 - Sep 2018\n",
      "•Created a mock data generator based on data types for testing the billing amount of any product or offer launched\n",
      "by the client. It ensured a faster resolution of testing requests using the Kenan FX billing software application.\n",
      "•Developed automation test suite in HP-QTP automation tool to perform sanity testing every day and regression\n",
      "testing every release.\n",
      "•Worked on Linux and Unix systems, infra tools, SOAP UI for API testing, HP QTP automation tool.\n",
      "•Worked on UAT Testing, Product Testing, Regression Testing, Sanity Testing, and Environment Maintenance/code\n",
      "deployment in UAT environments.\n",
      "•Resolved successfully many severity-1 functional and environmental defects without any escalations from clients.\n",
      "CERTIFICATION\n",
      "•Deep Learning Specialization certification by deeplearning.ai\n",
      "•Python for Everybody specialization by University of Michigan\n",
      "•Leetcode Bootcamp Beginner by NYU Tandon Career Services\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import docx2txt\n",
    "import textract\n",
    "from bs4 import BeautifulSoup  # For handling HTML files\n",
    "import subprocess\n",
    "\n",
    "def convert_to_text(input_file):\n",
    "    \"\"\"\n",
    "    Attempts to convert the given input file to text based on its extension.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input file.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text content or None if conversion fails.\n",
    "    \"\"\"\n",
    "    filename, extension = os.path.splitext(input_file)\n",
    "\n",
    "    if extension.lower() == \".pdf\":\n",
    "        try:\n",
    "            pdf_file = open(input_file, 'rb')\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "            pdf_file.close()\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing PDF: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif extension.lower() == \".docx\":\n",
    "        try:\n",
    "            with open(input_file, 'rb') as docx_file:\n",
    "                text = docx2txt.process(docx_file)\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing docx: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif extension.lower() == \".html\":\n",
    "        try:\n",
    "            with open(input_file, 'r') as html_file:\n",
    "                html_content = html_file.read()\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            # Extract text, preserving newlines (if desired)\n",
    "            text = soup.get_text(separator='\\n')  # Use '\\n' for newline preservation\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing HTML: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif extension.lower() == \".tex\":\n",
    "        try:\n",
    "            # Use subprocess to run pdftotext command to convert LaTeX to text\n",
    "            pdftotext_cmd = f\"pdftotext -layout {input_file} -\"\n",
    "            process = subprocess.Popen(pdftotext_cmd, shell=True, stdout=subprocess.PIPE)\n",
    "            text, _ = process.communicate()\n",
    "            return text.decode('utf-8')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing LaTeX: {e}\")\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            # Attempt conversion using textract for other file types\n",
    "            text = textract.process(input_file).decode('utf-8')\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing other file type: {e}\")\n",
    "            return None\n",
    "\n",
    "# Example usage\n",
    "input_file_path = \"resume.pdf\"  # Replace with your actual file path\n",
    "text = convert_to_text(input_file_path)\n",
    "\n",
    "if text:\n",
    "    print(text)\n",
    "else:\n",
    "    print(\"Failed to convert file to text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b26e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b758b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
